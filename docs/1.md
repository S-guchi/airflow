# ステップ1: Airflowの全体像と準備

## Airflowとは
- PythonでDAG（有向非巡回グラフ）としてワークフローを記述し、スケジューラがワーカーに配信する。
- 主要コンポーネント: Webserver（UI）, Scheduler, Worker, Metadata DB, Executor（Celery/Local/Sequential など）。
- 現行の安定版 3.1 系（2025-12-12 時点）は Python 3.10–3.13 でテストされ、最小 4GB メモリが推奨。MariaDB は非サポート、SQLite は学習用のみに推奨。citeturn1search5

## 学習の進め方（このリポジトリでの段階）
1. Docker Compose でローカル起動して UI を触る（次のステップへ）。
2. はじめての DAG を書き、依存関係・スケジュールを体感する。
3. TaskFlow API で Pythonic に書き直し、XCom/データ受け渡しを理解する。
4. 変数・接続、テスト、運用のベストプラクティスに進む。

## 事前に用意するもの
- Docker Desktop（メモリ 4GB 以上を割り当て）と docker compose v2.14 以降。citeturn1search0
- POSIX 系 OS または macOS（Windows は WSL2 で動作）。citeturn1search5
- Python が書ければ十分。初期セットアップは Docker だけで完結。

次は `docs/2.md` でローカル環境を立ち上げます。
